# LLM Implementation envs
# The following are just examples of the adapter implementation, you can have completely different envs
AZURE_LARGE_LLM_MODEL="gpt-4o"
AZURE_LARGE_LLM_API_VERSION="2024-12-01-preview"
AZURE_LARGE_LLM_ENDPOINT="https://yourproject.openai.azure.com"
AZURE_LLM_SUBSCRIPTION_KEY="xyz"

# Embedding envs
# The following are just examples of the adapter implementation, you can have completely different envs
AZURE_EMBEDDING_FULL_ENDPOINT="https://yourproject.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2023-05-15"
AZURE_EMBEDDING_KEY="xyz"

# Cache envs
# The following are just examples of the adapter implementation, you can have completely different envs
REDIS_HOST="localhost"
REDIS_PORT=6379

# Worker envs
# Can be whatever you prefer
# CELERY_BACKEND="rabbitmq"
CELERY_BACKEND="redis"

# GraphDB envs
# The following are just examples of the adapter implementation, you can have completely different envs
NEO4J_HOST="localhost"
NEO4J_PORT=7687
NEO4J_USERNAME="neo4j"
NEO4J_PASSWORD="your_password"

# VectorDB envs
# The following are just examples of the adapter implementation, you can have completely different envs
MILVUS_HOST="localhost"
MILVUS_PORT=19530

# DataDB envs
# The following are just examples of the adapter implementation, you can have completely different envs
MONGO_HOST="localhost"
MONGO_PORT=27017
MONGO_USERNAME="root"
MONGO_PASSWORD="password"

# Auth
# Used to handle authentication
BRAINPAT_TOKEN="your_token"
